{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susanliang/opt/anaconda3/envs/nlp/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.decomposition import TruncatedSVD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_ranking = pd.read_csv('./young_company/qs_rank_2024.csv', index_col=0)\n",
    "different_rows = pd.read_csv('institutions_full.csv', header= None)\n",
    "different_rows = different_rows.rename(columns={0: \"index\", 1: \"institution_name\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### University Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### this section first clean the QS university table and then map the university to the standard QS university name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_rank = pd.read_excel(\"2024 QS World University Rankings 1.2 (For qs.com) copy.xlsx\")\n",
    "raw_rank.columns = [None] * raw_rank.shape[1]\n",
    "raw_rank = raw_rank.drop(index=[0, 1])\n",
    "raw_rank = raw_rank.reset_index()\n",
    "new_header = raw_rank.iloc[0] \n",
    "raw_rank = raw_rank[1:] \n",
    "raw_rank.columns = new_header \n",
    "raw_rank = raw_rank.drop(columns=[2, 'rank display2','location code'])\n",
    "raw_rank = raw_rank.rename(columns={\"rank display\": \"rank_2024\"})\n",
    "raw_rank = raw_rank.iloc[:, :3]\n",
    "raw_rank['institution'] = raw_rank['institution'].str.replace(r'\\s*\\(.*\\)', '', regex=True)\n",
    "raw_rank = raw_rank.replace(r'[=+]', '', regex=True)\n",
    "raw_rank['rank_2024'] = raw_rank['rank_2024'].astype(str)\n",
    "def convert_to_numeric(value):\n",
    "    if '-' in value:\n",
    "        start, end = map(int, value.split('-'))\n",
    "        return (start + end) / 2\n",
    "    else:\n",
    "        return int(value)\n",
    "\n",
    "raw_rank['rank_2024'] = raw_rank['rank_2024'].apply(convert_to_numeric).astype(int)\n",
    "qs_ranking = raw_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_rows['Best Match'] = None\n",
    "different_rows = different_rows.astype(str)\n",
    "different_rows = different_rows[different_rows['Best Match'] == 'None']\n",
    "\n",
    "sample_university_names = different_rows[different_rows['Best Match'] == 'None']['institution_name'].tolist()\n",
    "qs_standard_names = qs_ranking['institution'].tolist()\n",
    "# Load the Sentence-BERT model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "qs_embeddings = model.encode(qs_standard_names, convert_to_tensor=True) # create embeddings for QS standard names\n",
    "\n",
    "# Function to find the best match for each name based on cosine similarity\n",
    "def match_with_embeddings(name, qs_names, qs_embeddings, threshold=0.6):\n",
    "    name_embedding = model.encode(name, convert_to_tensor=True)\n",
    "    # Compute cosine similarity between the name and each QS name\n",
    "    similarities = util.cos_sim(name_embedding, qs_embeddings)[0]\n",
    "    best_score = torch.max(similarities).item()\n",
    "    best_match_idx = torch.argmax(similarities).item()\n",
    "    best_match = qs_names[best_match_idx] if best_score >= threshold else None\n",
    "    return best_match\n",
    "\n",
    "semantic_matches = {}\n",
    "for name in tqdm(sample_university_names, desc=\"Matching university names\"):\n",
    "    semantic_matches[name] = match_with_embeddings(name, qs_standard_names, qs_embeddings)\n",
    "\n",
    "print(semantic_matches)\n",
    "\n",
    "different_rows = different_rows.astype(str)\n",
    "different_rows = different_rows[different_rows['Best Match'] != 'None']\n",
    "\n",
    "matches_df = pd.DataFrame.from_dict(semantic_matches, orient='index', columns=['Best Match'])\n",
    "matches_df.index.name = 'institution_name' \n",
    "matches_df.reset_index(inplace=True)\n",
    "# matches_df.to_excel('BERT_matches_dfv2.xlsx')\n",
    "matches_df = pd.DataFrame.from_dict(semantic_matches, orient='index', columns=['Best Match'])\n",
    "matches_df.index.name = 'institution_name' \n",
    "matches_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### this section generate SQL statements which can be directly copy-paste into mysql. The mapping output version currently being used for mysql scripts are further being revised manually to ensure there is no meaningless mapping. However, for the sake of workflow, the mapping result is directly translated into mysql code without further manual verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_statements = []\n",
    "matches_df = matches_df.astype(str)\n",
    "for _, row in matches_df.iterrows():\n",
    "    new_name = row['Best Match'].replace(\"'\", \"''\")  # Handle single quotes\n",
    "    old_name = row['institution_name'].replace(\"'\", \"''\")   # Handle single quotes\n",
    "    sql = f\"UPDATE young_company.institutions SET institution_name = '{new_name}' WHERE institution_name = '{old_name}';\"\n",
    "    update_statements.append(sql)\n",
    "\n",
    "sql_updates = \"\\n\".join(update_statements)\n",
    "print(\"Generated SQL UPDATE statements:\")\n",
    "print(sql_updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### University Program Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### this section applys topic generation and top modelling to the university study programs of the founders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susanliang/opt/anaconda3/envs/nlp/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 6:\n",
      "['Mathematics' 'Mathematics And Computer Science'\n",
      " 'Engineering Mathematics']\n",
      "\n",
      "Cluster 45:\n",
      "['Industrial And Management Engineering'\n",
      " 'Econometrics, Industrial Economics' 'Industrial Design, Daap']\n",
      "\n",
      "Cluster 7:\n",
      "['Engineering, Applied Mathematics'\n",
      " 'Bachelor Of Applied Science Computer Engineering'\n",
      " 'Applied Economics And Management']\n",
      "\n",
      "Cluster 22:\n",
      "['Physics, Math' 'Math And Physics' 'Chinese And Math']\n",
      "\n",
      "Cluster 11:\n",
      "['Applied Operations Research'\n",
      " 'Operations Research, Financial Engineering'\n",
      " 'Operations Research And Industrial Engineering']\n",
      "\n",
      "Cluster 48:\n",
      "['Information Systems And Tools For New Media'\n",
      " 'Business Honors And Management Information Systems, Elements Of Computing Certificate'\n",
      " 'Information Management And Systems']\n",
      "\n",
      "Cluster 26:\n",
      "['International Studies, Focus On Brazil / Portuguese Language'\n",
      " 'International Baccalaureate' 'International Middle School']\n",
      "\n",
      "Cluster 34:\n",
      "['Economics And Finance, Minor In Statistics'\n",
      " 'Honours Mathematics, Statistics Major' 'Statistics, Mathematics']\n",
      "\n",
      "Cluster 28:\n",
      "['Machine Intelligence' 'Biomedical Engineering With Machine Learning'\n",
      " 'Mathematics, Computer Vision, Machine Learning']\n",
      "\n",
      "Cluster 23:\n",
      "['Computer Engineering Computer Science' 'Electrical Computer Engineering'\n",
      " 'Electrical Engineering, Computer Science, Management']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('programs_founder.csv', header=None)\n",
    "df = df.rename(columns={0: \"index\", 1: \"program_name\"})\n",
    "\n",
    "# Step 1: Text vectorization\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(df['program_name'])\n",
    "\n",
    "# Step 2: Dimensionality reduction for speedup\n",
    "# Reducing TF-IDF dimensionality with TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=100, random_state=42)\n",
    "X_reduced = svd.fit_transform(X)\n",
    "\n",
    "# Step 3: Clustering with reduced dimensions\n",
    "num_clusters = 50\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "df['Cluster'] = kmeans.fit_predict(X_reduced)\n",
    "\n",
    "sample_clusters = np.random.choice(df['Cluster'].unique(), 10, replace=False)\n",
    "\n",
    "for cluster in sample_clusters:\n",
    "    print(f\"\\nCluster {cluster + 1}:\")\n",
    "    print(df[df['Cluster'] == cluster]['program_name'].sample(3, random_state=42).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We take the 50 cluster output from above to chatGPT using GPT -4o model with the prompts as follows:\n",
    "\n",
    "`create 15 names of those 50 clusters, such as computer science, mathemetics, .... that will be further cosine similarity friendly`\n",
    "\n",
    "##### Then, I create a excel table from the GenAI tag generation result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now, I use LLM transformer to tag the university study programs into those 15 tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying programs: 100%|██████████| 3388/3388 [00:51<00:00, 65.71it/s]\n",
      "/var/folders/wr/956qfj8n0nd7qf20gnbgf5qw0000gn/T/ipykernel_45792/4007075045.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  programs_df['category'] = assigned_categories\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "programs_df = df[['index', 'program_name']]  \n",
    "categories_df = pd.read_excel('program_category_output.xlsx') \n",
    "category_embeddings = model.encode(categories_df['Program_Category'].tolist(), convert_to_tensor=True)\n",
    "assigned_categories = []\n",
    "for program_name in tqdm(programs_df['program_name'], desc=\"Classifying programs\"):\n",
    "    program_embedding = model.encode(program_name, convert_to_tensor=True)\n",
    "    similarities = util.pytorch_cos_sim(program_embedding, category_embeddings)\n",
    "    best_match_idx = int(similarities.argmax())\n",
    "    best_category = categories_df.iloc[best_match_idx]['Program_Category']\n",
    "    assigned_categories.append(best_category)\n",
    "programs_df['category'] = assigned_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# programs_df.to_csv('mapping_program_category.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
